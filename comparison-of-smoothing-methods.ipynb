{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Comparison of Basis Expansions in Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginners in machine learning often write off regression methods after learning of more exotic algorithms like Boosting, Random Forests, and Support Vector machines; why bother with a *linear* method when powerful non-parametric methods are readily avalable?\n",
    "\n",
    "It's easy to point out that the *linear* in linear regression is not meant to convey that the resulting model predictions are linear in the raw *feaure*, just the estimated parameters!  The modeler can certainly capture non-linearities in thier regression, they only need to transform the raw predictors!\n",
    "\n",
    "A common response is that it is error prone and  annoying work to explore data by hand and somehow divine correct transformations of predictors: other methods do it automatically.\n",
    "\n",
    "Ususally the only truly flexible method beginners learn to capture non-linearities in regression is polynomial regression, which is a real shame, as it is about the worst performing method available.\n",
    "\n",
    "The purpose of this post is to spread awareness of better options for capturing non-lineararities in regression models, we would like to advocate more widespread adoption of linear and cubic splines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "The idea for this post is based on my answer to [hxd1011](https://stats.stackexchange.com/users/113777/hxd1011)s [question regarding grouping vs. splines](https://stats.stackexchange.com/questions/230750/when-should-we-discretize-bin-continuous-independent-variables-features-and-when) at CrossValidated.\n",
    "\n",
    "### Software\n",
    "\n",
    "I've taken the oppurtunity to write a small [python module](https://github.com/madrury/basis-expansions) that is useful for using the basis expansions in this post here.  It conforms to the sklearn transfrmation interface, so can be used in pipelines and other high level processes in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis Expansions in Regression\n",
    "\n",
    "To capture non-linearities in regression models, we need to transform some or all of the predictors.  To avoid having to treat every predictor as a special case needing investigation, we would like some way of applying a very general *family* of transformations to our predictors, which is flexible enough to adapt (when the model is fit) to a wide variety of shapes.\n",
    "\n",
    "This takes the general form of a *basis expansion*.  Basis here is used in the linear algebraic sense: a linearly independent set of objects.  In this case our objects are *functions*:\n",
    "\n",
    "$$ B = f_1, f_2, \\ldots, f_k $$\n",
    "\n",
    "and we create new sets of features by applying every function in our basis to the given feature:\n",
    "\n",
    "$$ f_1(x), \\ f_2(x), \\ \\ldots, \\ f_k(x) $$\n",
    "\n",
    "\n",
    "### Polynomial Expansion\n",
    "\n",
    "The most commonly, and often *only*, example taught in introductory modeling courses or textbooks is **polynomial regression**.\n",
    "\n",
    "In polynomial regression we choose as our basis a set of polynomial terms of increasing degree:\n",
    "\n",
    "$$ f_1(x) = x, \\ f_2(x) = x^2, \\ \\ldots, \\ f_k(x) = x^k $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
